{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Research Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "MODEL_NAME = 'gemini/gemini-2.0-flash-exp'\n",
    "\n",
    "openai_client = openai.OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tys\\AppData\\Roaming\\Python\\Python311\\site-packages\\pypdf\\_crypt_providers\\_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from this module in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pypdf import PdfReader\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(filename):\n",
    "    \"\"\"\n",
    "    Extracts and returns the concatenated text from all pages of a given PDF file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        str: The concatenated text of the PDF.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reader = PdfReader(filename)\n",
    "        return ''.join(page.extract_text() for page in reader.pages)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the PDF: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "\n",
    "def get_completion(prompt, system='', history=[]):\n",
    "    try:\n",
    "        user_question = re.search(\"<question>([\\s\\S]*?)<\\/question>\", prompt).group(1)\n",
    "    except:\n",
    "        user_question = prompt\n",
    "\n",
    "    # Prepare the conversation history for OpenAI API\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] if system else []\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    # Call OpenAI API\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=MODEL_NAME,  # Specify the model to use\n",
    "        messages=messages,  # The conversation history\n",
    "        temperature=0.0, # make sure the llm output in deterministic way\n",
    "    )\n",
    "\n",
    "    # Extract the assistant's response\n",
    "    response_text = response.choices[0].message.content\n",
    "\n",
    "    # Update history\n",
    "    history.extend([f\"question: {user_question}\", f\"answer: {response_text}\"])\n",
    "    history_msg = \"</n>\".join(history)\n",
    "\n",
    "    return response_text, history_msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_TOPIC = \"stroke prediction\"\n",
    "\n",
    "PROMPT = \"\"\"\n",
    "You will be acting as an academmic researcher. Your goal is to study and find insights from the research papers.\n",
    "\n",
    "You should maintain a professional tone when writing your response.\n",
    "\n",
    "Here is the research paper:\n",
    "<document>\n",
    "{RESEARCH_PAPER}\n",
    "</document>\n",
    "\n",
    "Please go through the paper carefully and fill out all of these components to the best of your ability based on the information provided. Let me know if any component is not applicable or cannot be found.\n",
    "\n",
    "Here is the conversation history (between the user and you) prior to the question. It could be empty if there is no history.\n",
    "<history>{HISTORY}</history>\n",
    "\n",
    "Here is the user's question: \n",
    "<question>{QUESTION}</question>\n",
    "\n",
    "Think about your answer first before you respond. Put your response in <response></response> tags.\n",
    "\"\"\"\n",
    "HISTORY = []\n",
    "\n",
    "QUESTION = f\"\"\"\n",
    "I need you to carefully read through the attached research paper and extract the key details related to the following components:\n",
    "\n",
    "Here is the list of components to extract from the research paper:\n",
    "\n",
    "- \"author_name\": \"Name(s) of the author(s).\"\n",
    "-\"title\": \"Title of the research paper.\"\n",
    "- \"journal\": \"Name of the journal where the paper is published.\" \n",
    "- \"data_sources\": \"Data sources used in the research (if any).\"\n",
    "- \"sample\": \"Characteristics of the sample (if any).\" ,\n",
    "- \"independent_variables\": \"Independent variable(s).\" ,\n",
    "- \"dependent_variables\": \"Dependent variable(s).\" ,\n",
    "- \"factors_affecting_topic\": \"Factors affecting the research topic, with relevant statistics if applicable.\" ,\n",
    "- \"data_balancing_techniques\": \"Data balancing techniques used (if mentioned).\" ,\n",
    "- \"check1_data_balancing_techniques\": \"Check if the data balancing is applied to y_test? \",\n",
    "- \"check2_data_balancing_techniques\": \"Check if the data balancing is applied before or after train test split \",\n",
    "- \"missing_value_imputation\": \"Missing value imputation techniques (if any).\" ,\n",
    "- \"outlier_handling\": \"Techniques used to handle outliers (if any).\" ,\n",
    "- \"prediction_models\": \"Prediction models used in the study.\" ,\n",
    "- \"innovative_methods\": \"Innovative methods like machine learning replacing traditional techniques.\" ,\n",
    "- \"feature_importance_insights\": \"Insights from feature importance in modeling risk factors.\" ,\n",
    "- \"assumed_risk_factors\": \"Assumed risk factors before modeling.\" ,\n",
    "- \"explainability_implementation\": \"Implementation for explainable or interpretable machine learning.\" ,\n",
    "- \"research_objectives\": \"Research objectives.\" ,\n",
    "- \"research_design\": \"Research design and methodology.\" ,\n",
    "- \"key_findings\": \"Key research findings or outcomes.\" ,\n",
    "- \"future_implications\": \"Implications for future research.\" ,\n",
    "- \"performance_metrics\": \"Performance metrics of the prediction models.\" ,\n",
    "- \"research_gaps\": \"Identified research gaps.\" ,\n",
    "- \"related_works\": \"Related works mentioned in the paper.\" \n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "pdf_files = current_dir.glob(\"*.pdf\")  # Match all PDF files in the directory\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    research_paper = extract_text_from_pdf(pdf_file)\n",
    "\n",
    "    # Assume `get_completion` is defined elsewhere\n",
    "    completion, history_msg = get_completion(PROMPT.format(\n",
    "        RESEARCH_PAPER=research_paper, HISTORY=[], QUESTION=QUESTION))\n",
    "    \n",
    "    # print(f\"Processing: {pdf_file}\")\n",
    "    # print(completion)\n",
    "    \n",
    "    # Write the completion to a text file\n",
    "    output_file = pdf_file.with_suffix(\".txt\")\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{pdf_file}\\n==================================\\n{completion}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
